{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97140512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94fb9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import find_nearest_index, align_pulse, split_pulses\n",
    "from models.models_icp import ArtifactsDetectionModel, ResNet1D\n",
    "from models.models_abp import ShallowResNet1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9bff2ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icp_artifacts_model = ArtifactsDetectionModel()\n",
    "icp_artifacts_model.load_state_dict(torch.load(Path(r'models\\icp\\artifacts.pt')))\n",
    "\n",
    "icp_general_model = ResNet1D()\n",
    "icp_general_model.load_state_dict(torch.load(Path(r'models\\icp\\general_class.pth')))\n",
    "\n",
    "icp_subclass_0_1_model = ResNet1D()\n",
    "icp_subclass_0_1_model.load_state_dict(torch.load(Path(r'models\\icp\\subclasses_t0_t1.pth')))\n",
    "\n",
    "icp_subclass_2_3_4_model = ResNet1D(num_classes=3)\n",
    "icp_subclass_2_3_4_model.load_state_dict(torch.load(Path(r'models\\icp\\subclasses_t2_t3_t4.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccb849d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abp_artifacts_model = ArtifactsDetectionModel(num_classes=2)\n",
    "abp_artifacts_model.load_state_dict(torch.load(Path(r'models\\abp\\artifacts.pt')))\n",
    "\n",
    "abp_general_model = ShallowResNet1D()\n",
    "abp_general_model.load_state_dict(torch.load(Path(r'models\\abp\\general_class.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a4b4a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_predict(model, inputs, batch_size=1024, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    confs = []\n",
    "    loader = DataLoader(TensorDataset(inputs), batch_size=batch_size)\n",
    "    with torch.no_grad():\n",
    "        for (batch,) in loader:\n",
    "            batch = batch.to(device)\n",
    "            logits = model(batch)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            conf, pred = torch.max(probs, dim=1)\n",
    "            preds.append(pred.cpu())\n",
    "            confs.append(conf.cpu())\n",
    "    return torch.cat(preds), torch.cat(confs)\n",
    "\n",
    "def get_icp_class(waveforms, model_artifacts, model_general, model_subclass_normal, model_subclass_pathological,\n",
    "    confidence_threshold=0.0, batch_size=1024, device='cuda'):\n",
    "\n",
    "    waveforms = waveforms.to(dtype=torch.float32)\n",
    "    final_preds = torch.full((waveforms.shape[0],), -2, dtype=torch.long)\n",
    "\n",
    "    preds_valid, conf_valid = batched_predict(model_artifacts, waveforms, batch_size=batch_size, device=device)\n",
    "    confident_valid_mask = conf_valid >= confidence_threshold\n",
    "    artifact_mask = (preds_valid == 2) & (preds_valid == 1) & confident_valid_mask\n",
    "\n",
    "    final_preds[artifact_mask] = -1\n",
    "    valid_mask = ~artifact_mask\n",
    "\n",
    "    preds_general, _ = batched_predict(model_general, waveforms)\n",
    "    normal_mask = preds_general == 0\n",
    "    pathological_mask = preds_general == 1\n",
    "\n",
    "    preds_subclass_normal, _ = batched_predict(model_subclass_normal, waveforms)\n",
    "    final_preds[valid_mask & normal_mask] = preds_subclass_normal[valid_mask & normal_mask]\n",
    "\n",
    "    preds_subclass_pathological, _ = batched_predict(model_subclass_pathological, waveforms)\n",
    "    final_preds[valid_mask & pathological_mask] = preds_subclass_pathological[valid_mask & pathological_mask] + 2\n",
    "\n",
    "    return final_preds\n",
    "\n",
    "\n",
    "def get_abp_class(waveforms, model_artifacts, model_general,\n",
    "    confidence_threshold=0.0, batch_size=1024, device='cuda'):\n",
    "\n",
    "    waveforms = waveforms.to(dtype=torch.float32)\n",
    "    final_preds = torch.full((waveforms.shape[0],), -2, dtype=torch.long)\n",
    "\n",
    "    preds_valid, conf_valid = batched_predict(model_artifacts, waveforms)\n",
    "    confident_valid_mask = conf_valid >= confidence_threshold\n",
    "    artifact_mask = (preds_valid == 1) & confident_valid_mask\n",
    "    \n",
    "    final_preds[artifact_mask] = -1\n",
    "    valid_mask = ~artifact_mask\n",
    "\n",
    "    preds_general, _ = batched_predict(model_general, waveforms)\n",
    "    final_preds[valid_mask] = preds_general[valid_mask]\n",
    "\n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ecfb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pulses(time, signal, start_indices, end_indices, output_len=180, device='cpu'):\n",
    "    if not isinstance(signal, torch.Tensor):\n",
    "        signal = torch.tensor(signal, dtype=torch.float32)\n",
    "\n",
    "    signal = signal.to(device)\n",
    "    start_indices = torch.tensor(start_indices, dtype=torch.long, device=device)\n",
    "    end_indices = torch.tensor(end_indices, dtype=torch.long, device=device)\n",
    "\n",
    "    times = []\n",
    "    waveforms = []\n",
    "    for start, end in zip(start_indices, end_indices):\n",
    "        t = time[start:end]\n",
    "        pulse = signal[start:end]\n",
    "        pulse = align_pulse(t, pulse)\n",
    "\n",
    "        pulse = (pulse - pulse.min()) / (pulse.max() - pulse.min())\n",
    "\n",
    "        pulse = pulse.unsqueeze(0).unsqueeze(0)\n",
    "        resampled = F.interpolate(pulse, size=output_len, mode='linear', align_corners=False)\n",
    "\n",
    "        waveforms.append(resampled.squeeze(0))\n",
    "        times.append(t[0])\n",
    "\n",
    "    return torch.stack(waveforms, dim=0), times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a8ea6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(r'd:\\Data\\Preludium\\Preludium_release\\PAC03_FULL_SIGNALS.pkl')\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    t = data['t']\n",
    "    icp = data['icp']\n",
    "    abp = data['abp']\n",
    "    fs = data['fs_hat']\n",
    "\n",
    "start_time = t[0]\n",
    "end_idx = find_nearest_index(t, start_time + 2 * 60 * 60)\n",
    "\n",
    "t = t[:end_idx]\n",
    "icp = icp[:end_idx]\n",
    "abp = abp[:end_idx]\n",
    "\n",
    "_, _, pulse_onsets_icp = split_pulses(icp, t, fs)\n",
    "_, _, pulse_onsets_abp = split_pulses(abp, t, fs)\n",
    "\n",
    "pulse_starts_icp = pulse_onsets_icp[:-1]\n",
    "pulse_ends_icp = pulse_onsets_icp[1:]\n",
    "pulses_icp, times_icp = extract_pulses(t, icp, pulse_starts_icp, pulse_ends_icp)\n",
    "\n",
    "pulse_starts_abp = pulse_onsets_abp[:-1]\n",
    "pulse_ends_abp = pulse_onsets_abp[1:]\n",
    "pulses_abp, times_abp = extract_pulses(t, abp, pulse_starts_abp, pulse_ends_abp)\n",
    "\n",
    "predictions_icp = get_icp_class(pulses_icp, icp_artifacts_model, icp_general_model, icp_subclass_0_1_model, icp_subclass_2_3_4_model)\n",
    "predictions_icp = predictions_icp.detach().cpu().numpy()\n",
    "\n",
    "predictions_abp = get_abp_class(pulses_abp, abp_artifacts_model, abp_general_model)\n",
    "predictions_abp = predictions_abp.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22f93905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4], dtype=int64), array([   7,    5,   16, 6331,   12], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(predictions_icp, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404312a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pulses_icp = pulses_icp.detach().cpu().numpy()\n",
    "pulses_icp = [arr for arr in pulses_icp] \n",
    "for idp, pulse in enumerate(pulses_icp):\n",
    "    f = plt.figure()\n",
    "    plt.plot(pulse)\n",
    "    # plt.title(predictions_icp[idp])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311465a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pulses_icp))         # list? ndarray? tensor?\n",
    "print(type(pulses_icp[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0577f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(predictions_abp, return_counts=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icmpgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
